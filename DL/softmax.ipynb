{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL ~softmax.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/3CGZBCg+FfbdH06s1Dlf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cf8ae7c7e334d4aa9c839af801d956d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bae182c4a61f47cdb577091d9f04c5bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_244e2e54b5af4ceb90ab60e76cfb7ee0",
              "IPY_MODEL_bd6832fa7c644aac8c26f0c7fe478fa3",
              "IPY_MODEL_686475c37a0547be91b2da73fe1725dd"
            ]
          }
        },
        "bae182c4a61f47cdb577091d9f04c5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "244e2e54b5af4ceb90ab60e76cfb7ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_991aa22051294652b5adb7c26e4ff9da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7585a386c8064145a6fe1812176db1ba"
          }
        },
        "bd6832fa7c644aac8c26f0c7fe478fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25c006e46bd843439f78998efff36044",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce0ee5f3ba044b8d9d9d32b1052bb73b"
          }
        },
        "686475c37a0547be91b2da73fe1725dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_623c83f2cdd848a4ad202b07b12daffd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 54941981.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41bd6b79cca9498db08f04c6059a50fd"
          }
        },
        "991aa22051294652b5adb7c26e4ff9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7585a386c8064145a6fe1812176db1ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25c006e46bd843439f78998efff36044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce0ee5f3ba044b8d9d9d32b1052bb73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "623c83f2cdd848a4ad202b07b12daffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41bd6b79cca9498db08f04c6059a50fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyun-ho-Lee/Python-Practice/blob/main/DL_~softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2vqWvuOUpf1"
      },
      "source": [
        "import numpy as np \n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnfLKt6zJStU",
        "outputId": "4681bf44-e8d9-49f6-870d-87e08e4d8ef7"
      },
      "source": [
        "m1 = torch.FloatTensor([[1,2]])\n",
        "m2 = torch.FloatTensor([[3],[4]])\n",
        "\n",
        "print(m1 + m2)\n",
        "\n",
        "#텐서의 경우 1x2 배열은 2x2 배열로바꿈 즉 2x2가 기본 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4., 5.],\n",
            "        [5., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfn0Y6IwKAWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ed9a8b-8bb4-4157-a369-6e8381caa98d"
      },
      "source": [
        "m1 = torch.FloatTensor([[1,2],[3,4]])\n",
        "m2 = torch.FloatTensor([[1],[2]])\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4attzrJ9kaqY",
        "outputId": "e9fcf5f9-2f03-4055-d168-3b1dde6dcba1"
      },
      "source": [
        "print()\n",
        "print('-------------')\n",
        "print('Mul vs Matmul')\n",
        "print('-------------')\n",
        "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
        "m2 = torch.FloatTensor([[1], [2]])\n",
        "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
        "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
        "print(m1.matmul(m2)) # 2 x 1    matmul의 경우 \n",
        "\n",
        "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
        "m2 = torch.FloatTensor([[1], [2]])\n",
        "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
        "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
        "print(m1 * m2) # 2 x 2\n",
        "print(m1.mul(m2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------\n",
            "Mul vs Matmul\n",
            "-------------\n",
            "Shape of Matrix 1:  torch.Size([2, 2])\n",
            "Shape of Matrix 2:  torch.Size([2, 1])\n",
            "tensor([[ 5.],\n",
            "        [11.]])\n",
            "Shape of Matrix 1:  torch.Size([2, 2])\n",
            "Shape of Matrix 2:  torch.Size([2, 1])\n",
            "tensor([[1., 2.],\n",
            "        [6., 8.]])\n",
            "tensor([[1., 2.],\n",
            "        [6., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt4nip1hm71b",
        "outputId": "94914457-9252-4676-eea7-76800fdedddc"
      },
      "source": [
        "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA8236ZwnGGV"
      },
      "source": [
        "#dim 0 은 행을 보존 dim 1 는 열을 보존한다는걸 꼭 기억  # argmax 행렬의 index값을 보존 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU5cIytjoyRu",
        "outputId": "1c91ae24-42f4-44c7-9cf2-3131034fd339"
      },
      "source": [
        "t = np.array([[[0, 1, 2],\n",
        "               [3, 4, 5]],\n",
        "\n",
        "              [[6, 7, 8],\n",
        "               [9, 10, 11]]])\n",
        "ft = torch.FloatTensor(t)\n",
        "print(ft.shape)\n",
        "\n",
        "#3차원 공간으로 나타냄 \n",
        "\n",
        "print(ft.view([-1,3]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URYbCkmXp-ci",
        "outputId": "2f098d20-8a81-4c68-ee0c-c0b667bbde44"
      },
      "source": [
        "ft = torch.FloatTensor([[0],[1],[2]])\n",
        "print(ft)\n",
        "print(ft.shape)\n",
        "print(ft.squeeze())\n",
        "print(ft.squeeze().shape)\n",
        "print(ft.squeeze(dim=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.]])\n",
            "torch.Size([3, 1])\n",
            "tensor([0., 1., 2.])\n",
            "torch.Size([3])\n",
            "tensor([0., 1., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuMHWGQaq9QP",
        "outputId": "64a13033-3e5c-44a4-aca4-eb92a00cf327"
      },
      "source": [
        "#unsqueez \n",
        "\n",
        "ft = torch.Tensor([0, 1, 2]) #3개 element 1d vector \n",
        "print(ft.shape) \n",
        "print(ft.unsqueeze(0)) #dim = 0 \n",
        "print(ft.unsqueeze(0).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "tensor([[0., 1., 2.]])\n",
            "torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9eIMLXF5mkS",
        "outputId": "cdaf6ba0-4507-4612-b386-08f028249df5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f54c1c38bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcPBCEv9uQeg"
      },
      "source": [
        "X_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "\n",
        "W = torch.zeros(1,requires_grad=True)\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "hypothesis = X_train *W + b\n",
        "\n",
        "cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr=0.01)\n",
        "\n",
        "nb_epochs = 10000\n",
        "\n",
        "for epoch in range (1,nb_epochs +1):\n",
        "    hypothesis = X_train *W +b \n",
        "    cost =torch.mean((hypothesis - y_train)**2 )\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step( )\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "FqaoMe8z756B",
        "outputId": "b8132564-d28f-4c4c-88e0-d6a7a3733d5f"
      },
      "source": [
        "# multivariate Linear Regression \n",
        "\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "w = torch.zeros((3,1),requires_grad=True)\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr=1e-5)\n",
        "\n",
        "nb_epochs = 20 \n",
        "\n",
        "#for epoch in range(nb_epochs+1) : \n",
        "    #hypothesis = x_train.matmul(w) + b     # or .mm or @\n",
        "\n",
        "    #cost 계산 \n",
        "    #cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "    #cost로 H(x) 개선 \n",
        "    #optimizer.zero_grad()\n",
        "    #cost.backward()\n",
        "    #optimizer.step() \n",
        "    #print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            #epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        #))\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c15feb7bfd06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m     \u001b[0;31m# or .mm or @\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#cost 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4xYy1gQARp6"
      },
      "source": [
        "#기본 idea는 차원이 너무 복잡하지않게 처리하는게 우선 따라서  H=Xw+b 로 나타낼수있음 위 식같은경우 x1 x2 ..일일이 다 정의 해줘야하는데 행렬화시킬경우 쉽게 가능함\n",
        "\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5G6T43GAmLA",
        "outputId": "6b59ca4e-848a-4539-d4be-3099a480fcc9"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "# 가중치와 편향 선언\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# W가 (3,1)인 이유는 (5,3) 이므로 차원을 맞춰줘야한다\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
        "    hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 1])\n",
            "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch    1/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost: 9537.694336\n",
            "Epoch    2/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7862,  95.8280]) Cost: 3069.590088\n",
            "Epoch    3/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost: 990.670288\n",
            "Epoch    4/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost: 322.481873\n",
            "Epoch    5/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost: 107.717064\n",
            "Epoch    6/20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]) Cost: 38.687496\n",
            "Epoch    7/20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]) Cost: 16.499043\n",
            "Epoch    8/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]) Cost: 9.365656\n",
            "Epoch    9/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]) Cost: 7.071114\n",
            "Epoch   10/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost: 6.331847\n",
            "Epoch   11/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost: 6.092532\n",
            "Epoch   12/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]) Cost: 6.013817\n",
            "Epoch   13/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost: 5.986785\n",
            "Epoch   14/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]) Cost: 5.976325\n",
            "Epoch   15/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost: 5.971208\n",
            "Epoch   16/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost: 5.967835\n",
            "Epoch   17/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]) Cost: 5.964969\n",
            "Epoch   18/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost: 5.962291\n",
            "Epoch   19/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost: 5.959664\n",
            "Epoch   20/20 hypothesis: tensor([154.0536, 185.1134, 175.7451, 198.6145, 141.2158]) Cost: 5.957089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nBN9DhMDrI6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "\n",
        "#우리는 y=2x 즉 w=2 라는 답을 현재 알고있는 상태임 따라서 모델이 w=2와 b=0 인걸 제대로 찾아내는것이 목표 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILlooO2uEndq",
        "outputId": "3df840a2-e83b-4b5c-ed0f-ae6436e1ff6e"
      },
      "source": [
        "model = nn.Linear(1,1) #하나의 입력 x에 대해서 하나의 출력 y를 가지므로 입력 차원과 출력 차원 모두 1을 인수로 사용 \n",
        "print(list(model.parameters())) #model parameters 는 랜덤 초기화가 되어져 있음 \n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr =0.01)\n",
        "\n",
        "nb_epochs = 2000\n",
        "\n",
        "#까먹지 말아야할거 range경우 저기선 range(2000)인데 0부터1999까지 하는거이므로 마지막 하나가 누락 따라서 \"무조건\" +1 해줘야함 안하면 큰일남 ㄹㅇ 임 \n",
        "\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "    prediction =model(x_train)\n",
        "    \n",
        "    cost = F.mse_loss(prediction,y_train) # pytorch 에서 제공하는 평균 제곱 오차 함수 \n",
        "\n",
        "    #cost로 h(x) 개선\n",
        "    #gradient를 0 으로 초기화\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    #비용함수 미분하여 gradient 개선\n",
        "    cost.backward() #backward연산\n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n",
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx5e7Yi2KwV5",
        "outputId": "3835e8ba-75bf-461e-c271-e44b9b142c8f"
      },
      "source": [
        "#print 결과 cost가 0에 수렴하는걸 볼수가있음 따라서 W와b를 제대로 예측했는지 확인\n",
        "\n",
        "new_var = torch.FloatTensor([[4.0]]) \n",
        "new_var\n",
        "\n",
        "pred_y = model(new_var)\n",
        "\n",
        "pred_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.9989]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlpkBwUbXa8E",
        "outputId": "d33f97a1-ac56-4148-cb01-bca6c19b05d8"
      },
      "source": [
        "#모델이 pred_y를 7.9989 약 8로 예측을 함 \n",
        "\n",
        "\n",
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0Lr5soKXvF9"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_KmTWmVXymN",
        "outputId": "b8c9b81f-a151-4f7f-f3d1-d06392e36806"
      },
      "source": [
        "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
        "model = nn.Linear(3,1)\n",
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.5435,  0.3462, -0.1188]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2937], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsYIBHFZX9yM"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdEVDuq6X_59",
        "outputId": "a540ff12-f693-4240-f0d9-60f66abad38c"
      },
      "source": [
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward()\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 39633.414062\n",
            "Epoch  100/2000 Cost: 11.480746\n",
            "Epoch  200/2000 Cost: 10.894592\n",
            "Epoch  300/2000 Cost: 10.339335\n",
            "Epoch  400/2000 Cost: 9.813351\n",
            "Epoch  500/2000 Cost: 9.315010\n",
            "Epoch  600/2000 Cost: 8.842962\n",
            "Epoch  700/2000 Cost: 8.395753\n",
            "Epoch  800/2000 Cost: 7.972028\n",
            "Epoch  900/2000 Cost: 7.570637\n",
            "Epoch 1000/2000 Cost: 7.190376\n",
            "Epoch 1100/2000 Cost: 6.830142\n",
            "Epoch 1200/2000 Cost: 6.488811\n",
            "Epoch 1300/2000 Cost: 6.165472\n",
            "Epoch 1400/2000 Cost: 5.859105\n",
            "Epoch 1500/2000 Cost: 5.568909\n",
            "Epoch 1600/2000 Cost: 5.293931\n",
            "Epoch 1700/2000 Cost: 5.033408\n",
            "Epoch 1800/2000 Cost: 4.786575\n",
            "Epoch 1900/2000 Cost: 4.552718\n",
            "Epoch 2000/2000 Cost: 4.331151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnPKCYjIYDTS",
        "outputId": "77d3333f-09e1-4d9b-ae68-a21747b17c03"
      },
      "source": [
        "# 임의의 입력 [73, 80, 75]를 선언\n",
        "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
        "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var) \n",
        "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.9886]], grad_fn=<AddmmBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4A6qhr0YUxC"
      },
      "source": [
        "model = nn.Linear(1,1) #단순 회귀이므로 input 1 output 1 \n",
        "\n",
        "class LinearRegressionModel(nn.Module): # torch.nn.Module을 상속받는 파이썬 클래스\n",
        "    def __init__(self): # 모델의 구조와 동작을 정의하는 생성자 속성값을 초기화하는 역할 \n",
        "        super().__init__() #\n",
        "        self.linear = nn.Linear(1, 1) # 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = LinearRegressionModel()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXVgOCxTfR-o"
      },
      "source": [
        "model = nn.Linear(3,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFdWpwogf109"
      },
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = MultivariateLinearRegressionModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q9XwAt6k5Tm",
        "outputId": "12144b7e-4994-4c14-941c-71c3aa3c6749"
      },
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l907l1Rnma2l"
      },
      "source": [
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55zShZKKmbWL"
      },
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  90], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4SojUZqmdZs"
      },
      "source": [
        "dataset = TensorDataset(x_train, y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True) # shuffle을 사용할경우 Epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꿔줌\n",
        "\n",
        "model = nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9DZuMWPnMvi"
      },
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    print(batch_idx)\n",
        "    print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBSh65R5485_"
      },
      "source": [
        "class CustomDataset(torch.utils.data.Dataset): \n",
        "  def __init__(self):\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "  def __getitem__(self, idx): "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khPBEH_n5K2m"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZatZU305MPv"
      },
      "source": [
        "# Dataset 상속\n",
        "class CustomDataset(Dataset): \n",
        "  def __init__(self):\n",
        "    self.x_data = [[73, 80, 75],\n",
        "                   [93, 88, 93],\n",
        "                   [89, 91, 90],\n",
        "                   [96, 98, 100],\n",
        "                   [73, 66, 70]]\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "\n",
        "  # 총 데이터의 개수를 리턴\n",
        "  def __len__(self): \n",
        "    return len(self.x_data)\n",
        "\n",
        "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
        "  def __getitem__(self, idx): \n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCRWDLKx5XBu"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np # 넘파이 사용\n",
        "import matplotlib.pyplot as plt # 맷플롯립사용\n",
        "\n",
        "def sigmoid(x): \n",
        "    return 1/(1+np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "RAZsvYt35jjP",
        "outputId": "d18d3691-8175-49f2-f935-edcfe0277ad0"
      },
      "source": [
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = sigmoid(x)\n",
        "\n",
        "plt.plot(x, y, 'g')\n",
        "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
        "plt.title('Sigmoid Function')\n",
        "plt.show()\n",
        "\n",
        "#실제값 y와 예측값 H(x) 의 차이가 커지면 cost가 커지고 차이가 작아지면 cost가 작아짐 따라서 경사하강법을 수행하며 최적의 가중치 W를 찾아가야함"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR5-YXDg6glA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F17NP-Lm6lPm",
        "outputId": "6f409436-90f4-47e1-b77c-a3d9505efac7"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLIxPxKz6sr-"
      },
      "source": [
        "# Y = XW 가 되야하므로 \n",
        "\n",
        "W = torch.zeros((2,1),requires_grad=True)\n",
        "b = torch.zeros(1,requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2PA6jQP673x",
        "outputId": "2b434064-1740-40e7-bd2b-c897f06df215"
      },
      "source": [
        "hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPtKsbUc7HKA"
      },
      "source": [
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grtb_sAI7O3U",
        "outputId": "1d850f46-29d5-4289-fe95-37a313f7999d"
      },
      "source": [
        "losses = -(y_train * torch.log(hypothesis) + \n",
        "           (1 - y_train) * torch.log(1 - hypothesis))\n",
        "print(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931]], grad_fn=<NegBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXuoNXK37Q0N",
        "outputId": "f67983bc-d10c-48eb-e3c3-4f293138474b"
      },
      "source": [
        "cost = losses.mean()\n",
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH_W2-xh7hWG",
        "outputId": "47433c05-9196-4e4e-a793-2c47d549ff48"
      },
      "source": [
        "F.binary_cross_entropy(hypothesis, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mokft9TP7mhW",
        "outputId": "833e8c83-a112-400f-e8ef-79b1dbf79b89"
      },
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "    cost = -(y_train * torch.log(hypothesis) + \n",
        "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031673\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5x1guu7wp_",
        "outputId": "3199f0bc-752b-46b0-bd8c-190005ecf6ab"
      },
      "source": [
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.7648e-04],\n",
            "        [3.1608e-02],\n",
            "        [3.8977e-02],\n",
            "        [9.5622e-01],\n",
            "        [9.9823e-01],\n",
            "        [9.9969e-01]], grad_fn=<SigmoidBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuI6XLOR7mlY",
        "outputId": "04acca89-727e-4cc9-892e-0bad886432a4"
      },
      "source": [
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [ True],\n",
            "        [ True],\n",
            "        [ True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wnHefhr7_AH"
      },
      "source": [
        "model = nn.Sequential(\n",
        "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
        "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWXdrxIe8DQ5",
        "outputId": "467f1ff6-e24d-44e4-9d02-67ce0e7113ce"
      },
      "source": [
        "model(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6620],\n",
              "        [0.7082],\n",
              "        [0.5054],\n",
              "        [0.6447],\n",
              "        [0.6107],\n",
              "        [0.4862]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWBvELbv8JSd",
        "outputId": "6bac4f90-5c75-475a-8d78-5ba5e89a3281"
      },
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.778947 Accuracy 33.33%\n",
            "Epoch   10/1000 Cost: 0.606802 Accuracy 66.67%\n",
            "Epoch   20/1000 Cost: 0.446548 Accuracy 66.67%\n",
            "Epoch   30/1000 Cost: 0.376169 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.318945 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.268428 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.222594 Accuracy 100.00%\n",
            "Epoch   70/1000 Cost: 0.183695 Accuracy 100.00%\n",
            "Epoch   80/1000 Cost: 0.158160 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.144616 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.134716 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.126157 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.118640 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.111984 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.106051 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.100728 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.095925 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.091571 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.087604 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.083974 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.080641 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.077569 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.074728 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.072092 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.069641 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.067355 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.065218 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.063216 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.061336 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.059567 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.057899 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.056324 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.054835 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.053424 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.052085 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.050813 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.049603 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.048451 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047352 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046302 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045299 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044339 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043420 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.042539 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.041694 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.040882 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.040101 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039350 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.038628 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.037932 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037261 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036613 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.035988 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035384 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.034801 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034237 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.033691 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033162 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032650 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032153 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031672 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031205 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.030752 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030312 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.029885 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029469 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.029065 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028672 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028290 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.027918 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027556 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027203 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.026859 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026524 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026197 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.025878 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025567 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025263 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.024967 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024677 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024394 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024118 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.023848 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023584 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023325 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023073 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022826 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022584 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022347 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022115 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021888 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021666 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021448 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021234 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.021025 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020820 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020619 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020422 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020228 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.020038 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019852 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkaNu7558aJ4",
        "outputId": "c1d526cc-b6a2-4d0d-da60-983014ee1a03"
      },
      "source": [
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[3.2530, 1.5179]], requires_grad=True), Parameter containing:\n",
            "tensor([-14.4819], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EauyVimS8wCn"
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsb2QmwA80-f"
      },
      "source": [
        "model = BinaryClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbppDlYy82-I"
      },
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Wtihp7lI7J"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)\n",
        "z = torch.FloatTensor([1, 2, 3])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI1GZHANlNsa",
        "outputId": "a2acc7c1-1bcd-438a-c829-fbf65faf9365"
      },
      "source": [
        "hypothesis = F.softmax(z, dim=0)\n",
        "print(hypothesis)\n",
        "sum(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn81FIlplmeL",
        "outputId": "e814c9a5-6c72-4538-e558-b9110824cc85"
      },
      "source": [
        "z = torch.rand(3, 5, requires_grad=True)\n",
        "hypothesis = F.softmax(z, dim=1)\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
            "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
            "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzCbgPclF7gz",
        "outputId": "c5e74b36-b858-4c97-b01c-1fa9461c598b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f986f603bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQeuu0opFAa-"
      },
      "source": [
        "x_train = [[1, 2, 1, 1],\n",
        "           [2, 1, 3, 2],\n",
        "           [3, 1, 3, 4],\n",
        "           [4, 1, 5, 5],\n",
        "           [1, 7, 5, 5],\n",
        "           [1, 2, 5, 6],\n",
        "           [1, 6, 6, 6],\n",
        "           [1, 7, 7, 7]]\n",
        "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.LongTensor(y_train)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT0HE9vrMFIs",
        "outputId": "d27f396c-7e69-4441-9db5-3080b0b2a520"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4voqwe-FHDr",
        "outputId": "1b864486-4679-462a-9cb8-e4f1e1960218"
      },
      "source": [
        "#y_train을 one hot 해야함 현재는 8x1 형태이지만  클래스의 갯수가 3개이므로 8x3으로 변형해야함 \n",
        "y_one_hot = torch.zeros(8, 3)\n",
        "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
        "print(y_one_hot.shape)\n",
        "y_one_hot"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G-xgb1TFq7I",
        "outputId": "82b14a19-4e23-44e6-a97a-dbc4c6a3183b"
      },
      "source": [
        "#x train shpae 는 8x4 따라서 W는 4x3 이여야지 y 크기가 4x3이 나옴 \n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((4, 3), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.1) # 학습률 0.1 \n",
        "\n",
        "\n",
        "nb_epochs = 1000\n",
        "\n",
        "for epoch in range(nb_epochs +1):\n",
        "    hypothesis = F.softmax(x_train.matmul(W) + b ,dim =1 ) #가설 input 형태 \n",
        "    cost = (y_one_hot* -torch.log(hypothesis)).sum(dim=1).mean() # cost function \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "     # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))   "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.761050\n",
            "Epoch  200/1000 Cost: 0.689991\n",
            "Epoch  300/1000 Cost: 0.643229\n",
            "Epoch  400/1000 Cost: 0.604117\n",
            "Epoch  500/1000 Cost: 0.568255\n",
            "Epoch  600/1000 Cost: 0.533922\n",
            "Epoch  700/1000 Cost: 0.500291\n",
            "Epoch  800/1000 Cost: 0.466908\n",
            "Epoch  900/1000 Cost: 0.433507\n",
            "Epoch 1000/1000 Cost: 0.399962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6k1JZzyJ2yc",
        "outputId": "50cd48c3-5678-40fa-9cb6-b50247245e48"
      },
      "source": [
        "#F.cross_entropy()는 그 자체로 소프트맥스 함수를 포함\n",
        "# 모델 초기화\n",
        "W = torch.zeros((4, 3), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    z = x_train.matmul(W) + b\n",
        "    cost = F.cross_entropy(z, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.761050\n",
            "Epoch  200/1000 Cost: 0.689991\n",
            "Epoch  300/1000 Cost: 0.643229\n",
            "Epoch  400/1000 Cost: 0.604117\n",
            "Epoch  500/1000 Cost: 0.568256\n",
            "Epoch  600/1000 Cost: 0.533922\n",
            "Epoch  700/1000 Cost: 0.500291\n",
            "Epoch  800/1000 Cost: 0.466908\n",
            "Epoch  900/1000 Cost: 0.433507\n",
            "Epoch 1000/1000 Cost: 0.399962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1upXoY0aMUME",
        "outputId": "0a32296e-c255-42c3-81f9-55a5fbdcde8c"
      },
      "source": [
        "model = nn.Linear(4, 3)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.616785\n",
            "Epoch  100/1000 Cost: 0.658891\n",
            "Epoch  200/1000 Cost: 0.573443\n",
            "Epoch  300/1000 Cost: 0.518151\n",
            "Epoch  400/1000 Cost: 0.473265\n",
            "Epoch  500/1000 Cost: 0.433516\n",
            "Epoch  600/1000 Cost: 0.396563\n",
            "Epoch  700/1000 Cost: 0.360914\n",
            "Epoch  800/1000 Cost: 0.325392\n",
            "Epoch  900/1000 Cost: 0.289178\n",
            "Epoch 1000/1000 Cost: 0.254148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7j5JcRlMZ4K",
        "outputId": "048e4c7d-aeb1-4773-a4df-4fe8b33ff7a0"
      },
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(4, 3) # Output이 3!\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = SoftmaxClassifierModel()\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 2.637636\n",
            "Epoch  100/1000 Cost: 0.647903\n",
            "Epoch  200/1000 Cost: 0.564643\n",
            "Epoch  300/1000 Cost: 0.511043\n",
            "Epoch  400/1000 Cost: 0.467249\n",
            "Epoch  500/1000 Cost: 0.428281\n",
            "Epoch  600/1000 Cost: 0.391924\n",
            "Epoch  700/1000 Cost: 0.356742\n",
            "Epoch  800/1000 Cost: 0.321577\n",
            "Epoch  900/1000 Cost: 0.285617\n",
            "Epoch 1000/1000 Cost: 0.250818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDzj146xMxsH"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODs1S1laM26E",
        "outputId": "a39f2690-b984-4ae1-84b4-8ea4c1e8dbf4"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
        "print(\"다음 기기로 학습합니다:\", device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 기기로 학습합니다: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzaoWiZWNE24"
      },
      "source": [
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4lqgBCXNGvu"
      },
      "source": [
        "# hyperparameters\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489,
          "referenced_widgets": [
            "8cf8ae7c7e334d4aa9c839af801d956d",
            "bae182c4a61f47cdb577091d9f04c5bc",
            "244e2e54b5af4ceb90ab60e76cfb7ee0",
            "bd6832fa7c644aac8c26f0c7fe478fa3",
            "686475c37a0547be91b2da73fe1725dd",
            "991aa22051294652b5adb7c26e4ff9da",
            "7585a386c8064145a6fe1812176db1ba",
            "25c006e46bd843439f78998efff36044",
            "ce0ee5f3ba044b8d9d9d32b1052bb73b",
            "623c83f2cdd848a4ad202b07b12daffd",
            "41bd6b79cca9498db08f04c6059a50fd"
          ]
        },
        "id": "TEYKOansNHjk",
        "outputId": "874de139-ac20-4621-c49a-ec5861d3434b"
      },
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cf8ae7c7e334d4aa9c839af801d956d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "208c72afdbb242f7bcfbbf2b651ba697",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "586b064a77ff429daff277832645b0fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c481d1d670b74c93b860d77e12b3f8b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oli4lEO3NORU",
        "outputId": "4ba917e6-1d63-41aa-aff6-a7e63c66eba7"
      },
      "source": [
        "mnist_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: MNIST_data/\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX4aobL6NQpD"
      },
      "source": [
        "# dataset loader\n",
        "data_loader = DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size, # 배치 크기는 100\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True) \n",
        "\n",
        "#drop last의경우 100개있을때 배치크기가 128개일 경우 104개가 남음 마지막 배치가 과대평가될수있으므로 drop시킴"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKU-7igvNm2F"
      },
      "source": [
        "linear = nn.Linear(784, 10, bias=True).to(device) #input dim이 784 즉 28*28로 이루어져있고  output이 10 임"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDIdps0yN-UM"
      },
      "source": [
        "# 비용 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMHchPIxOGhs",
        "outputId": "f905d60a-1a2a-4773-8f9d-a21931d5589f"
      },
      "source": [
        "for epoch in range(training_epochs): # 앞서 training_epochs의 값은 15로 지정함.\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서가 된다.\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수.\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = linear(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 cost = 0.535899699\n",
            "Epoch: 0002 cost = 0.359200507\n",
            "Epoch: 0003 cost = 0.331210256\n",
            "Epoch: 0004 cost = 0.316642880\n",
            "Epoch: 0005 cost = 0.306912154\n",
            "Epoch: 0006 cost = 0.300341636\n",
            "Epoch: 0007 cost = 0.295203745\n",
            "Epoch: 0008 cost = 0.290808439\n",
            "Epoch: 0009 cost = 0.287419200\n",
            "Epoch: 0010 cost = 0.284378767\n",
            "Epoch: 0011 cost = 0.281997472\n",
            "Epoch: 0012 cost = 0.279780537\n",
            "Epoch: 0013 cost = 0.277854115\n",
            "Epoch: 0014 cost = 0.276023209\n",
            "Epoch: 0015 cost = 0.274494946\n",
            "Learning finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "gjvwGWkmOYXC",
        "outputId": "860b650e-e3a0-425d-c45f-c0e6691a5ebd"
      },
      "source": [
        "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "\n",
        "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
        "    r = random.randint(0, len(mnist_test) - 1)\n",
        "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "    print('Label: ', Y_single_data.item())\n",
        "    single_prediction = linear(X_single_data)\n",
        "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
        "    plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8841999769210815\n",
            "Label:  7\n",
            "Prediction:  7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
